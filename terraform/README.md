# RAG Agents - Terraform Infrastructure

Infraestructura como cÃ³digo para desplegar las Lambdas RAG y recursos asociados en AWS.

## ğŸ“ Estructura

```
terraform/
â”œâ”€â”€ main.tf                    # ConfiguraciÃ³n principal
â”œâ”€â”€ variables.tf               # DefiniciÃ³n de variables
â”œâ”€â”€ outputs.tf                 # Outputs del deployment
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ asap_main.tfvars       # Config para ambiente dev
â”‚   â””â”€â”€ prod.tfvars.example    # Ejemplo para producciÃ³n
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ aurora_postgres/       # MÃ³dulo Aurora PostgreSQL
â”‚   â”œâ”€â”€ lambda/                # MÃ³dulo Lambda genÃ©rico
â”‚   â””â”€â”€ s3_documents/          # MÃ³dulo S3 para documentos
â””â”€â”€ scripts/
    â”œâ”€â”€ deploy.sh              # Script de deploy
    â””â”€â”€ build-lambdas.sh       # Script de build
```

## ğŸš€ Quick Start

### Prerrequisitos

1. **AWS CLI** configurado con credenciales
2. **Terraform** >= 1.3.0
3. **Python** >= 3.12 (para build de lambdas)

### Deployment

```bash
# 1. Ir al directorio de terraform
cd terraform

# 2. Inicializar Terraform
terraform init

# 3. Crear/seleccionar workspace
terraform workspace new dev  # o: terraform workspace select dev

# 4. Ver plan de cambios
terraform plan -var-file=environments/asap_main.tfvars

# 5. Aplicar cambios
terraform apply -var-file=environments/asap_main.tfvars
```

### Usando el script de deploy

```bash
# Ver plan
./scripts/deploy.sh plan -e dev

# Aplicar cambios
./scripts/deploy.sh apply -e dev

# Aplicar con auto-approve
./scripts/deploy.sh apply -e dev -y

# Destruir recursos
./scripts/deploy.sh destroy -e dev
```

## ğŸ“¦ Recursos Creados

### Lambdas

| Lambda | DescripciÃ³n | Trigger |
|--------|-------------|---------|
| `rag_lmbd_embeddings` | Procesa PDFs, genera embeddings y guarda en PostgreSQL | S3 (*.pdf) |
| `rag_lmbd_query` | BÃºsqueda semÃ¡ntica + respuesta LLM | InvocaciÃ³n directa |

### Otros Recursos

- **S3 Bucket**: Para almacenar documentos PDF
- **Aurora PostgreSQL**: Base de datos con pgvector
- **IAM Roles**: Permisos para cada Lambda
- **Security Groups**: Acceso a RDS desde Lambdas
- **CloudWatch Log Groups**: Logs de las Lambdas

## âš™ï¸ Variables de ConfiguraciÃ³n

### Generales

| Variable | DescripciÃ³n | Default |
|----------|-------------|---------|
| `region` | RegiÃ³n de AWS | `us-east-1` |
| `aws_profile` | Perfil de AWS CLI | - |
| `environment` | Ambiente (dev/staging/prod) | - |

### Red

| Variable | DescripciÃ³n |
|----------|-------------|
| `vpc_id` | ID de la VPC |
| `subnets` | Lista de subnets (privadas recomendadas) |

### Aurora PostgreSQL

| Variable | DescripciÃ³n | Default |
|----------|-------------|---------|
| `master_username` | Usuario admin | - |
| `master_password` | Password admin | - |
| `engine_version` | VersiÃ³n de PostgreSQL | `14.11` |
| `aurora_min_capacity` | ACUs mÃ­nimos | `0.5` |
| `aurora_max_capacity` | ACUs mÃ¡ximos | `4` |

### Modelos Bedrock

| Variable | DescripciÃ³n | Default |
|----------|-------------|---------|
| `embeddings_model` | Modelo para embeddings | `cohere.embed-v4:0` |
| `main_llm_model` | Modelo LLM principal | `claude-3-5-sonnet` |
| `fallback_llm_model` | Modelo LLM fallback | `claude-3-haiku` |

## ğŸ” Seguridad

### Recomendaciones para ProducciÃ³n

1. **Secrets Manager**: Usar para credenciales de BD
   ```hcl
   # En lugar de:
   master_password = "plain_text_password"
   
   # Usar:
   master_password = data.aws_secretsmanager_secret_version.db.secret_string
   ```

2. **Subnets Privadas**: Las Lambdas deben estar en subnets privadas con NAT Gateway

3. **Security Groups**: Restringir CIDR blocks en lugar de `0.0.0.0/0`

4. **S3 Bucket Policy**: Restringir acceso al bucket de documentos

5. **VPC Endpoints**: Considerar endpoints para S3, Bedrock para reducir costos

## ğŸ“Š Arquitectura

```
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚    S3 Bucket        â”‚
                                    â”‚  (rag-documents-*)  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚ S3 Event
                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              VPC                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        Private Subnets                           â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚
â”‚  â”‚  â”‚  Lambda              â”‚      â”‚  Lambda              â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  rag_lmbd_embeddings â”‚      â”‚  rag_lmbd_query      â”‚        â”‚   â”‚
â”‚  â”‚  â”‚                      â”‚      â”‚                      â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ PDF Processing    â”‚      â”‚  â€¢ Semantic Search   â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Embeddings Gen    â”‚      â”‚  â€¢ LLM Response      â”‚        â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Store in DB       â”‚      â”‚  â€¢ Query Embeddings  â”‚        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚
â”‚  â”‚             â”‚                             â”‚                     â”‚   â”‚
â”‚  â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚   â”‚
â”‚  â”‚                            â”‚                                    â”‚   â”‚
â”‚  â”‚                            â–¼                                    â”‚   â”‚
â”‚  â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚   â”‚
â”‚  â”‚             â”‚    Aurora PostgreSQL     â”‚                       â”‚   â”‚
â”‚  â”‚             â”‚    (with pgvector)       â”‚                       â”‚   â”‚
â”‚  â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                           â”‚
                    â–¼                           â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Amazon Bedrock  â”‚         â”‚ Amazon Textract â”‚
          â”‚ (Embeddings/LLM)â”‚         â”‚ (PDF OCR)       â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§ª Testing

### Subir un documento

```bash
# Estructura: s3://bucket/tenant_id/agent_id/filename.pdf
aws s3 cp documento.pdf s3://rag-documents-dev-123456789012/tenant_asap/agent_123/documento.pdf
```

### Invocar Lambda de Query

```bash
aws lambda invoke \
  --function-name rag_lmbd_query-dev \
  --payload '{"query": "Â¿QuÃ© es arquitectura hexagonal?", "tenant_id": "tenant_asap", "agent_id": "agent_123"}' \
  --cli-binary-format raw-in-base64-out \
  response.json

cat response.json
```

### Ver logs

```bash
# Logs de embeddings
aws logs tail /aws/lambda/rag_lmbd_embeddings-dev --follow

# Logs de query
aws logs tail /aws/lambda/rag_lmbd_query-dev --follow
```

## ğŸ”„ CI/CD

### GitHub Actions (ejemplo)

```yaml
name: Deploy Infrastructure

on:
  push:
    branches: [main]
    paths:
      - 'terraform/**'
      - 'apps/rag_lmbd_*/**'

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Terraform Init
        run: terraform init
        working-directory: terraform
      
      - name: Terraform Plan
        run: terraform plan -var-file=environments/prod.tfvars
        working-directory: terraform
      
      - name: Terraform Apply
        if: github.ref == 'refs/heads/main'
        run: terraform apply -var-file=environments/prod.tfvars -auto-approve
        working-directory: terraform
```

## ğŸ› ï¸ Troubleshooting

### Lambda no puede conectar a RDS

1. Verificar que la Lambda estÃ¡ en la misma VPC que Aurora
2. Verificar que el Security Group permite trÃ¡fico en puerto 5432
3. Verificar que las subnets tienen acceso a internet (NAT Gateway)

### Lambda timeout procesando PDF

1. Aumentar `timeout` en la configuraciÃ³n (mÃ¡x 900s)
2. Aumentar `memory_size` para PDFs grandes
3. Verificar tamaÃ±o del PDF y considerar chunking

### Error de permisos Bedrock

1. Verificar que el modelo estÃ¡ habilitado en la cuenta
2. Verificar la polÃ­tica IAM incluye el modelo correcto
3. Verificar la regiÃ³n del modelo

## ğŸ“ Notas

- Los workspaces de Terraform permiten manejar mÃºltiples ambientes
- El state de Terraform se guarda localmente por defecto
- Para producciÃ³n, configurar backend S3 para el state
